{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R5_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d6719fa55ba5429f95205f3f454f74d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_65ec879a2e10447ea2e25c9077668d86",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8a785e95e1f44cbeb4683501c0e4d8ee",
              "IPY_MODEL_91c21f23ea1746beb4fa4d9f13e3951f"
            ]
          }
        },
        "65ec879a2e10447ea2e25c9077668d86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a785e95e1f44cbeb4683501c0e4d8ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a02f890ef85f42c6af951da087da66d7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a37b1281fd54af683d44070edff580e"
          }
        },
        "91c21f23ea1746beb4fa4d9f13e3951f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e819fdf2b37541a2b6229dcc0d2cff18",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/? [00:02&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c844f1b06d1494a952e193ded2f9fc9"
          }
        },
        "a02f890ef85f42c6af951da087da66d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a37b1281fd54af683d44070edff580e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e819fdf2b37541a2b6229dcc0d2cff18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c844f1b06d1494a952e193ded2f9fc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jakartaresearch/quora-question-pairs/blob/master/R5_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDlE5n-Jap0M",
        "colab_type": "code",
        "outputId": "eb0c3bef-cfdc-4b3c-bf58-4bb3e836a065",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil --q\n",
        "!pip install psutil --q\n",
        "!pip install humanize --q\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 26.2 GB  | Proc size: 159.0 MB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KinixNmEA1Mi",
        "colab_type": "text"
      },
      "source": [
        "# 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH15tJAM8tc0",
        "colab_type": "code",
        "outputId": "02e0af30-6531-4836-9fd9-11edf53807ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "d6719fa55ba5429f95205f3f454f74d4",
            "65ec879a2e10447ea2e25c9077668d86",
            "8a785e95e1f44cbeb4683501c0e4d8ee",
            "91c21f23ea1746beb4fa4d9f13e3951f",
            "a02f890ef85f42c6af951da087da66d7",
            "2a37b1281fd54af683d44070edff580e",
            "e819fdf2b37541a2b6229dcc0d2cff18",
            "2c844f1b06d1494a952e193ded2f9fc9"
          ]
        }
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive # import drive from google colab\n",
        "\n",
        "ROOT = \"/content/drive/\"     # default location for the drive\n",
        "drive.mount(ROOT)           # we mount the google drive at /content/drive\n",
        "\n",
        "import pickle\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import numpy as np\n",
        "from tqdm import tqdm_notebook, tqdm\n",
        "tqdm_notebook().pandas()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6719fa55ba5429f95205f3f454f74d4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0WYXOnZ7s3-",
        "colab_type": "text"
      },
      "source": [
        "## 1.1 Using Colab GPU for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncHH9X9H2oqV",
        "colab_type": "code",
        "outputId": "386aae0b-9818-4a9c-f03e-91aa6446c4d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJYNoCEi7xMQ",
        "colab_type": "text"
      },
      "source": [
        "## 1.2 Install Hugging Face library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua52hPaj7LPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers --q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBsQyFBq71zE",
        "colab_type": "text"
      },
      "source": [
        "# 2. Load Quora Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDpUUROmahM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = 'drive/My Drive/Colab Notebooks/quora-question-pairs/data/'\n",
        "kfold_folder = glob.glob(data_path+'cross_validation_data/*')\n",
        "train_id_file = '/train_id.csv'\n",
        "val_id_file = '/val_id.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWMEOn5xakRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_csv(path):\n",
        "    data = pd.read_csv(path)\n",
        "    return data\n",
        "\n",
        "def remove_row_nan(df):\n",
        "    df = df.dropna(axis = 0)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN9Cj69pappb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(data_path+'quora_duplicate_questions.tsv', sep='\\t')\n",
        "data = remove_row_nan(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgulEG8bbH9H",
        "colab_type": "code",
        "outputId": "a1bb3011-7dc7-4b0a-f0d3-c2c0974b31ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "train_kf = []\n",
        "val_kf = [] \n",
        "\n",
        "for kf, path in enumerate(kfold_folder,1):\n",
        "    print('Load KFold data from =', path)\n",
        "    print('KFold -',kf)\n",
        "    train_id = read_csv(path + train_id_file)\n",
        "    val_id = read_csv(path + val_id_file)\n",
        "\n",
        "    # Get specific data by id\n",
        "    train = data[data.id.isin(train_id.id.values)]\n",
        "    val = data[data.id.isin(val_id.id.values)]\n",
        "\n",
        "    # random sample data\n",
        "    train = train.sample(frac=1, random_state=42)\n",
        "    val = val.sample(frac=1, random_state=42)\n",
        "    train_kf.append(train)\n",
        "    val_kf.append(val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load KFold data from = drive/My Drive/Colab Notebooks/quora-question-pairs/data/cross_validation_data/5\n",
            "KFold - 1\n",
            "Load KFold data from = drive/My Drive/Colab Notebooks/quora-question-pairs/data/cross_validation_data/3\n",
            "KFold - 2\n",
            "Load KFold data from = drive/My Drive/Colab Notebooks/quora-question-pairs/data/cross_validation_data/2\n",
            "KFold - 3\n",
            "Load KFold data from = drive/My Drive/Colab Notebooks/quora-question-pairs/data/cross_validation_data/1\n",
            "KFold - 4\n",
            "Load KFold data from = drive/My Drive/Colab Notebooks/quora-question-pairs/data/cross_validation_data/4\n",
            "KFold - 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Mr3OGkU_dio",
        "colab_type": "text"
      },
      "source": [
        "# 3. Tokenization & Input Formatting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9prBry5a_Wnl",
        "colab_type": "code",
        "outputId": "fd28390d-4d6c-44a4-faea-fb4c7c60bd15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSfnMPoQAMvG",
        "colab_type": "code",
        "outputId": "4d300487-1b2b-41a5-b79d-11ff94ccd0a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import statistics\n",
        "sent_length = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in tqdm(data.question1):\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "    sent_length.append(len(input_ids))\n",
        "\n",
        "for sent in tqdm(data.question2):\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "    sent_length.append(len(input_ids))\n",
        "\n",
        "print('')\n",
        "print('Average length = ', sum(sent_length)/len(sent_length))\n",
        "print('Median length = ', statistics.median(sent_length))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 404287/404287 [01:21<00:00, 4973.25it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 404287/404287 [01:19<00:00, 5063.46it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Average length =  16.124631759121613\n",
            "Median length =  14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Np2aBSm5HXdK",
        "colab_type": "text"
      },
      "source": [
        "Max length di set menjadi 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBU1L41PzLj1",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghIRKJzPHL9C",
        "colab_type": "code",
        "outputId": "0584b3a7-c0e2-414b-9dad-ee8c2b52d330",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "ListTrainDataset = []\n",
        "ListValDataset = []\n",
        "train_data = True\n",
        "\n",
        "# for train and validation data\n",
        "for purpose_data in [train_kf, val_kf]:\n",
        "    print('Processing Train Data') if train_data == True else print('Processing Validation Data')\n",
        "    # for every KFold data\n",
        "    for kf in tqdm(range(5)):\n",
        "        print('KFold-', kf+1)\n",
        "        # Tokenize all of the sentences and map the tokens to their word IDs.\n",
        "        input_ids = []\n",
        "        token_type_ids = []\n",
        "        attention_masks = []\n",
        "\n",
        "        for sent in purpose_data[kf].itertuples():\n",
        "            encoded_dict = tokenizer.encode_plus(\n",
        "                                text = sent.question1,\n",
        "                                text_pair = sent.question2,                      # Sentence to encode.\n",
        "                                add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                                max_length = 64,           # Pad & truncate all sentences.\n",
        "                                pad_to_max_length = True,\n",
        "                                return_attention_mask = True,   # Construct attn. masks.\n",
        "                                return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                            )\n",
        "            \n",
        "            input_ids.append(encoded_dict['input_ids'])\n",
        "            token_type_ids.append(encoded_dict['token_type_ids'])\n",
        "            attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "        # Convert the lists into tensors.\n",
        "        input_ids = torch.cat(input_ids, dim=0)\n",
        "        token_type_ids = torch.cat(token_type_ids, dim=0)\n",
        "        attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "        if train_data == True :\n",
        "            labels = torch.tensor(train_kf[kf].is_duplicate.values)\n",
        "            ListTrainDataset.append({'input_ids':input_ids, 'token_type_ids':token_type_ids,\n",
        "                                'attention_masks':attention_masks, 'labels':labels})\n",
        "            print('Train Dataset done for KFold-', kf+1)\n",
        "        else :\n",
        "            labels = torch.tensor(val_kf[kf].is_duplicate.values)\n",
        "            ListValDataset.append({'input_ids':input_ids, 'token_type_ids':token_type_ids,\n",
        "                                'attention_masks':attention_masks, 'labels':labels})\n",
        "            print('Validation Dataset done for KFold-', kf+1)\n",
        "            \n",
        "    train_data = False"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing Train Data\n",
            "KFold- 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|â–ˆâ–ˆ        | 1/5 [02:17<09:10, 137.72s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Dataset done for KFold- 1\n",
            "KFold- 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [04:36<06:54, 138.02s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Dataset done for KFold- 2\n",
            "KFold- 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [06:53<04:35, 137.58s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Dataset done for KFold- 3\n",
            "KFold- 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [09:10<02:17, 137.59s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Dataset done for KFold- 4\n",
            "KFold- 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [11:27<00:00, 137.53s/it]\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Dataset done for KFold- 5\n",
            "Processing Validation Data\n",
            "KFold- 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|â–ˆâ–ˆ        | 1/5 [00:34<02:16, 34.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Dataset done for KFold- 1\n",
            "KFold- 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:08<01:42, 34.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Dataset done for KFold- 2\n",
            "KFold- 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:42<01:08, 34.10s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Dataset done for KFold- 3\n",
            "KFold- 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:16<00:34, 34.15s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Dataset done for KFold- 4\n",
            "KFold- 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [02:50<00:00, 34.11s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Dataset done for KFold- 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhT1IsmW66RZ",
        "colab_type": "code",
        "outputId": "f2414e3e-a497-422b-bb64-27acd6fdd1fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "## Save Dataset to pickle\n",
        "with open(data_path+'ListTrainDataset.pkl', 'wb') as f:\n",
        "    pickle.dump(ListTrainDataset, f)\n",
        "with open(data_path+'ListValDataset.pkl', 'wb') as f:\n",
        "    pickle.dump(ListValDataset, f)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
            "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnZCm6d5cLtc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Load Dataset from pickle\n",
        "ListTrainDataset = pickle.load(open(data_path+'ListTrainDataset.pkl', 'rb'))\n",
        "ListValDataset = pickle.load(open(data_path+'ListValDataset.pkl', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgSbgr3pPSmq",
        "colab_type": "text"
      },
      "source": [
        "# 4. Train Our Classification Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_N0umjEPac8",
        "colab_type": "text"
      },
      "source": [
        "## 4.1. BertForSequenceClassification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWwozSM5Pt6O",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "We'll be using [BertForSequenceClassification](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#bertforsequenceclassification). This is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA3x1UxuPO_2",
        "colab_type": "code",
        "outputId": "c371974d-3321-45d3-a5df-b90314bab984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-cased', # Use the 12-layer BERT model, with an cased vocab.\n",
        "    num_labels = 2, \n",
        "    output_attentions = False, # return attentions weights\n",
        "    output_hidden_states = False, # returns all hidden-states\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yUd50eRRCDr",
        "colab_type": "text"
      },
      "source": [
        "## 4.2. Optimizer & Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCBTpQpmRGnE",
        "colab_type": "text"
      },
      "source": [
        "Untuk fine-tuning, the authors recommend choosing from the following values (from Appendix A.3 of the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf)):\n",
        "\n",
        ">- **Batch size:** 16, 32  \n",
        "- **Learning rate (Adam):** 5e-5, 3e-5, 2e-5  \n",
        "- **Number of epochs:** 2, 3, 4 \n",
        "\n",
        "We chose:\n",
        "* Batch size: 32 (set when creating our DataLoaders)\n",
        "* Learning rate: 2e-5\n",
        "* Epochs: 3\n",
        "\n",
        "The epsilon parameter `eps = 1e-8` is \"a very small number to prevent any division by zero in the implementation\" (from [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWjSdRVVQ0p5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, \n",
        "                  eps = 1e-8\n",
        "                )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKS78j5vRqaB",
        "colab_type": "text"
      },
      "source": [
        "## 4.3. Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RcbEkN7Rw6d",
        "colab_type": "text"
      },
      "source": [
        "**Training:**\n",
        "- Unpack our data inputs and labels\n",
        "- Load data to GPU\n",
        "- Clear out the gradients calculated in the previous pass. \n",
        "- Forward pass (feed input data through the network)\n",
        "- Backward pass (backpropagation)\n",
        "- Tell the network to update parameters with optimizer.step()\n",
        "- Track variables for monitoring progress\n",
        "\n",
        "**Evalution:**\n",
        "- Unpack our data inputs and labels\n",
        "- Load data to GPU\n",
        "- Forward pass (feed input data through the network)\n",
        "- Compute loss on our validation data and track variables for monitoring progress"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9H5Gc9bSD9M",
        "colab_type": "text"
      },
      "source": [
        "Define a helper function for calculating accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsJsG7mVRdn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QJd7XJiSJRF",
        "colab_type": "text"
      },
      "source": [
        "Helper function for formatting elapsed times as `hh:mm:ss`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Egi63SNSFzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LM8SCN5ISPfF",
        "colab_type": "text"
      },
      "source": [
        "Ready to kick off the training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM2Hri3TSLy1",
        "colab_type": "code",
        "outputId": "d6ba2080-81d1-4ef4-cd04-64f42f716e31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 3\n",
        "batch_size = 32\n",
        "\n",
        "# List variable for store training and validation loss, validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each KFold\n",
        "for kf in range(1):\n",
        "    print('============= Data KFold-{:} ============='.format(kf+1))\n",
        "    # unpack value, and create TensorDataset\n",
        "    t_input_ids, t_token_type_ids, t_attention_mask, t_labels = ListTrainDataset[kf].values()\n",
        "    train_dataset = TensorDataset(t_input_ids, t_token_type_ids, t_attention_mask, t_labels)\n",
        "    # DataLoader for train dataset\n",
        "    train_dataloader = DataLoader(train_dataset, sampler = RandomSampler(train_dataset), batch_size = batch_size)\n",
        "    \n",
        "    # unpack value, and create TensorDataset\n",
        "    v_input_ids, v_token_type_ids, v_attention_mask, v_labels = ListValDataset[kf].values()\n",
        "    val_dataset = TensorDataset(v_input_ids, v_token_type_ids, v_attention_mask, v_labels)\n",
        "    # DataLoader for val dataset\n",
        "    validation_dataloader = DataLoader(val_dataset, sampler = SequentialSampler(val_dataset), batch_size = batch_size)\n",
        "    \n",
        "    # Create the learning rate scheduler.\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)\n",
        "\n",
        "\n",
        "    # For each epoch...\n",
        "    for epoch_i in range(0, epochs):\n",
        "        \n",
        "        # ========================================\n",
        "        #               Training\n",
        "        # ========================================\n",
        "        print(\"\")\n",
        "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        print('Training...')\n",
        "\n",
        "        # Measure how long the training epoch takes.\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Tracking metrics\n",
        "        total_train_loss = 0\n",
        "        total_train_accuracy = 0\n",
        "        total_train_f1 = 0\n",
        "        total_train_prec = 0\n",
        "        total_train_rec = 0\n",
        "\n",
        "        # Put the model into training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            # Progress update every 1000 batches.\n",
        "            if step % 1000 == 0 and not step == 0:\n",
        "                elapsed = format_time(time.time() - t0)\n",
        "                # Report progress.\n",
        "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "            # `batch` contains four pytorch tensors:\n",
        "            #   [0]: input ids\n",
        "            #   [1]: token_ids \n",
        "            #   [2]: attention masks\n",
        "            #   [3]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_token_ids = batch[1].to(device)\n",
        "            b_input_mask = batch[2].to(device)\n",
        "            b_labels = batch[3].to(device)\n",
        "\n",
        "            # Always clear any previously calculated gradients before performing a backward pass\n",
        "            model.zero_grad()        \n",
        "\n",
        "            # Perform a forward pass (evaluate the model on this training batch).\n",
        "            # token_type_ids is same as the \"segment ids\", which differentiates \n",
        "            # sentence 1 and 2 in sentence-pair tasks\n",
        "            loss, logits = model(b_input_ids, \n",
        "                                token_type_ids=b_token_ids,\n",
        "                                attention_mask=b_input_mask, \n",
        "                                labels=b_labels)\n",
        "\n",
        "            # Accumulate the training loss over all of the batches so that we can\n",
        "            # calculate the average loss at the end. \n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            # Move logits and labels to CPU\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "            # Calculate the accuracy for this batch and accumulate it over all batches.\n",
        "            total_train_accuracy += flat_accuracy(logits, label_ids)\n",
        "            total_train_f1 += f1_score(label_ids, np.argmax(logits, axis=1))\n",
        "            total_train_prec += precision_score(label_ids, np.argmax(logits, axis=1))\n",
        "            total_train_rec += recall_score(label_ids, np.argmax(logits, axis=1))\n",
        "\n",
        "            # Perform a backward pass to calculate the gradients.\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0.\n",
        "            # This is to help prevent the \"exploding gradients\" problem.\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and take a step using the computed gradient.\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the learning rate.\n",
        "            scheduler.step()\n",
        "\n",
        "        # Calculate the average loss and accuracy over all of the batches.\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "        avg_train_accuracy = total_train_accuracy / len(train_dataloader)\n",
        "        avg_train_f1 = total_train_f1 / len(train_dataloader)\n",
        "        avg_train_prec = total_train_prec / len(train_dataloader)\n",
        "        avg_train_rec = total_train_rec / len(train_dataloader)      \n",
        "        \n",
        "        # Measure how long this epoch took.\n",
        "        training_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"  Average loss: {0:.2f}\".format(avg_train_loss))\n",
        "        print(\"  Average accuracy: {0:.2f}\".format(avg_train_accuracy))\n",
        "        print(\"  Average f1: {0:.2f}\".format(avg_train_f1))\n",
        "        print(\"  Average prec: {0:.2f}\".format(avg_train_prec))\n",
        "        print(\"  Average rec: {0:.2f}\".format(avg_train_rec))  \n",
        "        print(\"  Training epoch took: {:}\".format(training_time))\n",
        "            \n",
        "        # ========================================\n",
        "        #               Validation\n",
        "        # ========================================\n",
        "        # After the completion of each training epoch, measure our performance on\n",
        "        # our validation set.\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Running Validation...\")\n",
        "\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Put the model in evaluation mode (batchnorm, dropout disable)\n",
        "        model.eval()\n",
        "\n",
        "        # Tracking metrics \n",
        "        total_eval_loss = 0\n",
        "        total_eval_accuracy = 0\n",
        "        total_eval_f1 = 0\n",
        "        total_eval_prec = 0\n",
        "        total_eval_rec = 0\n",
        "\n",
        "        # Evaluate data for one epoch\n",
        "        for batch in validation_dataloader:\n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_token_ids = batch[1].to(device)\n",
        "            b_input_mask = batch[2].to(device)\n",
        "            b_labels = batch[3].to(device)\n",
        "            \n",
        "            with torch.no_grad():        \n",
        "                # Forward pass, calculate logit predictions.\n",
        "                (loss, logits) = model(b_input_ids, \n",
        "                                      token_type_ids=b_token_ids, \n",
        "                                      attention_mask=b_input_mask,\n",
        "                                      labels=b_labels)\n",
        "                \n",
        "            # Accumulate the validation loss.\n",
        "            total_eval_loss += loss.item()\n",
        "\n",
        "            # Move logits and labels to CPU\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "            # Calculate the accuracy for this batch of test sentences, and\n",
        "            # accumulate it over all batches.\n",
        "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "            total_eval_f1 += f1_score(label_ids, np.argmax(logits, axis=1))\n",
        "            total_eval_prec += precision_score(label_ids, np.argmax(logits, axis=1))\n",
        "            total_eval_rec += recall_score(label_ids, np.argmax(logits, axis=1))\n",
        "            \n",
        "\n",
        "        # Report the final metrics\n",
        "        avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "        avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "        avg_val_f1 = total_eval_f1 / len(validation_dataloader)\n",
        "        avg_val_prec = total_eval_prec / len(validation_dataloader)\n",
        "        avg_val_rec = total_eval_rec / len(validation_dataloader)\n",
        "\n",
        "        # Measure how long the validation run took.\n",
        "        validation_time = format_time(time.time() - t0)\n",
        "        \n",
        "        print(\"  Average loss: {0:.2f}\".format(avg_val_loss))\n",
        "        print(\"  Average accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "        print(\"  Average f1: {0:.2f}\".format(avg_val_f1))\n",
        "        print(\"  Average prec: {0:.2f}\".format(avg_val_prec))\n",
        "        print(\"  Average rec: {0:.2f}\".format(avg_val_rec))\n",
        "        print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "        # Record all statistics from this epoch.\n",
        "        training_stats.append(\n",
        "            {    \n",
        "                'KFold': kf + 1, \n",
        "                'Epoch': epoch_i + 1,\n",
        "                'Training Loss': avg_train_loss,\n",
        "                'Validation Loss': avg_val_loss,\n",
        "                'Training Accuracy': avg_train_accuracy,\n",
        "                'Validation Accuracy': avg_val_accuracy,\n",
        "                'Training F1': avg_train_f1,\n",
        "                'Validation F1': avg_val_f1,\n",
        "                'Training Precision': avg_train_prec,\n",
        "                'Validation Precision': avg_val_prec,\n",
        "                'Training Recall': avg_train_rec,\n",
        "                'Validation Recall': avg_val_rec,\n",
        "                'Training Time': training_time,\n",
        "                'Validation Time': validation_time\n",
        "            }\n",
        "        )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "============= Data KFold-1 =============\n",
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch 1,000  of  10,108.    Elapsed: 0:03:29.\n",
            "  Batch 2,000  of  10,108.    Elapsed: 0:06:58.\n",
            "  Batch 3,000  of  10,108.    Elapsed: 0:10:27.\n",
            "  Batch 4,000  of  10,108.    Elapsed: 0:13:55.\n",
            "  Batch 5,000  of  10,108.    Elapsed: 0:17:23.\n",
            "  Batch 6,000  of  10,108.    Elapsed: 0:20:51.\n",
            "  Batch 7,000  of  10,108.    Elapsed: 0:24:19.\n",
            "  Batch 8,000  of  10,108.    Elapsed: 0:27:47.\n",
            "  Batch 9,000  of  10,108.    Elapsed: 0:31:16.\n",
            "  Batch 10,000  of  10,108.    Elapsed: 0:34:45.\n",
            "\n",
            "  Average loss: 0.15\n",
            "  Average accuracy: 0.94\n",
            "  Average f1: 0.92\n",
            "  Average prec: 0.91\n",
            "  Average rec: 0.94\n",
            "  Training epoch took: 0:35:08\n",
            "\n",
            "Running Validation...\n",
            "  Average loss: 0.29\n",
            "  Average accuracy: 0.90\n",
            "  Average f1: 0.86\n",
            "  Average prec: 0.86\n",
            "  Average rec: 0.88\n",
            "  Validation took: 0:02:32\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch 1,000  of  10,108.    Elapsed: 0:03:28.\n",
            "  Batch 2,000  of  10,108.    Elapsed: 0:06:56.\n",
            "  Batch 3,000  of  10,108.    Elapsed: 0:10:24.\n",
            "  Batch 4,000  of  10,108.    Elapsed: 0:13:52.\n",
            "  Batch 5,000  of  10,108.    Elapsed: 0:17:21.\n",
            "  Batch 6,000  of  10,108.    Elapsed: 0:20:48.\n",
            "  Batch 7,000  of  10,108.    Elapsed: 0:24:16.\n",
            "  Batch 8,000  of  10,108.    Elapsed: 0:27:45.\n",
            "  Batch 9,000  of  10,108.    Elapsed: 0:31:14.\n",
            "  Batch 10,000  of  10,108.    Elapsed: 0:34:42.\n",
            "\n",
            "  Average loss: 0.10\n",
            "  Average accuracy: 0.97\n",
            "  Average f1: 0.95\n",
            "  Average prec: 0.95\n",
            "  Average rec: 0.97\n",
            "  Training epoch took: 0:35:04\n",
            "\n",
            "Running Validation...\n",
            "  Average loss: 0.35\n",
            "  Average accuracy: 0.91\n",
            "  Average f1: 0.87\n",
            "  Average prec: 0.86\n",
            "  Average rec: 0.89\n",
            "  Validation took: 0:02:32\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch 1,000  of  10,108.    Elapsed: 0:03:27.\n",
            "  Batch 2,000  of  10,108.    Elapsed: 0:06:54.\n",
            "  Batch 3,000  of  10,108.    Elapsed: 0:10:21.\n",
            "  Batch 4,000  of  10,108.    Elapsed: 0:13:49.\n",
            "  Batch 5,000  of  10,108.    Elapsed: 0:17:16.\n",
            "  Batch 6,000  of  10,108.    Elapsed: 0:20:43.\n",
            "  Batch 7,000  of  10,108.    Elapsed: 0:24:10.\n",
            "  Batch 8,000  of  10,108.    Elapsed: 0:27:38.\n",
            "  Batch 9,000  of  10,108.    Elapsed: 0:31:05.\n",
            "  Batch 10,000  of  10,108.    Elapsed: 0:34:32.\n",
            "\n",
            "  Average loss: 0.06\n",
            "  Average accuracy: 0.98\n",
            "  Average f1: 0.97\n",
            "  Average prec: 0.97\n",
            "  Average rec: 0.98\n",
            "  Training epoch took: 0:34:54\n",
            "\n",
            "Running Validation...\n",
            "  Average loss: 0.45\n",
            "  Average accuracy: 0.91\n",
            "  Average f1: 0.87\n",
            "  Average prec: 0.87\n",
            "  Average rec: 0.88\n",
            "  Validation took: 0:02:32\n",
            "\n",
            "Training complete!\n",
            "Total training took 1:52:41 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGFUatydT5SW",
        "colab_type": "text"
      },
      "source": [
        "Let's view the summary of the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Db3I5BeSoMF",
        "colab_type": "code",
        "outputId": "c7adcb34-d512-45fd-ddec-ef761a93b26d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('Epoch')\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>KFold</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Training Accuracy</th>\n",
              "      <th>Validation Accuracy</th>\n",
              "      <th>Training F1</th>\n",
              "      <th>Validation F1</th>\n",
              "      <th>Training Precision</th>\n",
              "      <th>Validation Precision</th>\n",
              "      <th>Training Recall</th>\n",
              "      <th>Validation Recall</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0:35:08</td>\n",
              "      <td>0:02:32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0:35:04</td>\n",
              "      <td>0:02:32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0:34:54</td>\n",
              "      <td>0:02:32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       KFold  Training Loss  ...  Training Time  Validation Time\n",
              "Epoch                        ...                                \n",
              "1          1           0.15  ...        0:35:08          0:02:32\n",
              "2          1           0.10  ...        0:35:04          0:02:32\n",
              "3          1           0.06  ...        0:34:54          0:02:32\n",
              "\n",
              "[3 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9QSXQ0dX0c5",
        "colab_type": "code",
        "outputId": "01fad8dd-751b-47b9-befe-67253b5adbe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Accuracy'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Validation Accuracy'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0Gd_ohDAx9j",
        "colab_type": "text"
      },
      "source": [
        "# Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4zNM-kHAzah",
        "colab_type": "code",
        "outputId": "ecd0c365-2561-4b39-96ac-348434a58598",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = 'drive/My Drive/Colab Notebooks/quora-question-pairs/model/'\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to drive/My Drive/Colab Notebooks/quora-question-pairs/model/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('drive/My Drive/Colab Notebooks/quora-question-pairs/model/vocab.txt',\n",
              " 'drive/My Drive/Colab Notebooks/quora-question-pairs/model/special_tokens_map.json',\n",
              " 'drive/My Drive/Colab Notebooks/quora-question-pairs/model/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOJWg3dQiMCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}