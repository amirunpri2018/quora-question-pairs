{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_path = '../data/transformed'\n",
    "cross_val_path = '../data/cross_validation_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_cross_val_path = glob.glob(os.path.join(cross_val_path, '*', '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/transformed/data.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(os.path.join(transformed_path, '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_data = pickle.load(open('../data/transformed/data.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_clean</th>\n",
       "      <th>q2_clean</th>\n",
       "      <th>q1_token</th>\n",
       "      <th>q2_token</th>\n",
       "      <th>q1_vector</th>\n",
       "      <th>q2_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>224417</td>\n",
       "      <td>305276</td>\n",
       "      <td>428643</td>\n",
       "      <td>428644</td>\n",
       "      <td>Which kind of tea should we drink if we want t...</td>\n",
       "      <td>I don't like milk but I like drinking tea a lo...</td>\n",
       "      <td>0</td>\n",
       "      <td>kind tea drink want mix milk</td>\n",
       "      <td>like milk like drinking tea lot milk good vari...</td>\n",
       "      <td>[kind, tea, drink, want, mix, milk]</td>\n",
       "      <td>[like, milk, like, drinking, tea, lot, milk, g...</td>\n",
       "      <td>[0.0036476282, -0.014833373, -0.040485434, -0....</td>\n",
       "      <td>[-0.020281216, -0.076978564, 0.01739972, -0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>247342</td>\n",
       "      <td>328201</td>\n",
       "      <td>454706</td>\n",
       "      <td>454707</td>\n",
       "      <td>What are the opportunities after doing an MBA ...</td>\n",
       "      <td>What are the opportunities for an MBA in finance?</td>\n",
       "      <td>0</td>\n",
       "      <td>opportunities mba finance</td>\n",
       "      <td>opportunities mba finance</td>\n",
       "      <td>[opportunities, mba, finance]</td>\n",
       "      <td>[opportunities, mba, finance]</td>\n",
       "      <td>[0.013195766, -0.017697409, -0.015577622, 0.03...</td>\n",
       "      <td>[0.0044767293, -0.007943029, -0.015119746, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220551</td>\n",
       "      <td>301410</td>\n",
       "      <td>423210</td>\n",
       "      <td>424307</td>\n",
       "      <td>How do I have to learn english?</td>\n",
       "      <td>What is the easiest way to learn English?</td>\n",
       "      <td>0</td>\n",
       "      <td>learn english</td>\n",
       "      <td>easiest way learn english</td>\n",
       "      <td>[learn, english]</td>\n",
       "      <td>[easiest, way, learn, english]</td>\n",
       "      <td>[0.0041956515, -0.020153206, -0.0086065605, 0....</td>\n",
       "      <td>[0.059110086, 0.0052670497, -0.028890401, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>285439</td>\n",
       "      <td>366298</td>\n",
       "      <td>318327</td>\n",
       "      <td>496480</td>\n",
       "      <td>How is a Singapore GPA converted to Australian...</td>\n",
       "      <td>How do I convert my IIT CGPA to the USA GPA?</td>\n",
       "      <td>0</td>\n",
       "      <td>singapore gpa converted australian university ...</td>\n",
       "      <td>convert iit cgpa usa gpa</td>\n",
       "      <td>[singapore, gpa, converted, australian, univer...</td>\n",
       "      <td>[convert, iit, cgpa, usa, gpa]</td>\n",
       "      <td>[0.012895356, 0.018507749, 0.065207005, 0.0409...</td>\n",
       "      <td>[-0.012635684, 0.05562323, 0.08929469, 0.00817...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>207397</td>\n",
       "      <td>288256</td>\n",
       "      <td>409186</td>\n",
       "      <td>409187</td>\n",
       "      <td>What is the salary after gate?</td>\n",
       "      <td>Are Google's salaries on Glassdoor after taxes?</td>\n",
       "      <td>0</td>\n",
       "      <td>salary gate</td>\n",
       "      <td>google salaries glassdoor taxes</td>\n",
       "      <td>[salary, gate]</td>\n",
       "      <td>[google, salaries, glassdoor, taxes]</td>\n",
       "      <td>[-0.024693614, -0.008471563, 0.06587361, -0.02...</td>\n",
       "      <td>[-0.016694807, 0.012628836, 0.023681683, 0.045...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index      id    qid1    qid2  \\\n",
       "0  224417  305276  428643  428644   \n",
       "1  247342  328201  454706  454707   \n",
       "2  220551  301410  423210  424307   \n",
       "3  285439  366298  318327  496480   \n",
       "4  207397  288256  409186  409187   \n",
       "\n",
       "                                           question1  \\\n",
       "0  Which kind of tea should we drink if we want t...   \n",
       "1  What are the opportunities after doing an MBA ...   \n",
       "2                    How do I have to learn english?   \n",
       "3  How is a Singapore GPA converted to Australian...   \n",
       "4                     What is the salary after gate?   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  I don't like milk but I like drinking tea a lo...             0   \n",
       "1  What are the opportunities for an MBA in finance?             0   \n",
       "2          What is the easiest way to learn English?             0   \n",
       "3       How do I convert my IIT CGPA to the USA GPA?             0   \n",
       "4    Are Google's salaries on Glassdoor after taxes?             0   \n",
       "\n",
       "                                            q1_clean  \\\n",
       "0                       kind tea drink want mix milk   \n",
       "1                          opportunities mba finance   \n",
       "2                                      learn english   \n",
       "3  singapore gpa converted australian university ...   \n",
       "4                                        salary gate   \n",
       "\n",
       "                                            q2_clean  \\\n",
       "0  like milk like drinking tea lot milk good vari...   \n",
       "1                          opportunities mba finance   \n",
       "2                          easiest way learn english   \n",
       "3                           convert iit cgpa usa gpa   \n",
       "4                    google salaries glassdoor taxes   \n",
       "\n",
       "                                            q1_token  \\\n",
       "0                [kind, tea, drink, want, mix, milk]   \n",
       "1                      [opportunities, mba, finance]   \n",
       "2                                   [learn, english]   \n",
       "3  [singapore, gpa, converted, australian, univer...   \n",
       "4                                     [salary, gate]   \n",
       "\n",
       "                                            q2_token  \\\n",
       "0  [like, milk, like, drinking, tea, lot, milk, g...   \n",
       "1                      [opportunities, mba, finance]   \n",
       "2                     [easiest, way, learn, english]   \n",
       "3                     [convert, iit, cgpa, usa, gpa]   \n",
       "4               [google, salaries, glassdoor, taxes]   \n",
       "\n",
       "                                           q1_vector  \\\n",
       "0  [0.0036476282, -0.014833373, -0.040485434, -0....   \n",
       "1  [0.013195766, -0.017697409, -0.015577622, 0.03...   \n",
       "2  [0.0041956515, -0.020153206, -0.0086065605, 0....   \n",
       "3  [0.012895356, 0.018507749, 0.065207005, 0.0409...   \n",
       "4  [-0.024693614, -0.008471563, 0.06587361, -0.02...   \n",
       "\n",
       "                                           q2_vector  \n",
       "0  [-0.020281216, -0.076978564, 0.01739972, -0.06...  \n",
       "1  [0.0044767293, -0.007943029, -0.015119746, 0.0...  \n",
       "2  [0.059110086, 0.0052670497, -0.028890401, 0.02...  \n",
       "3  [-0.012635684, 0.05562323, 0.08929469, 0.00817...  \n",
       "4  [-0.016694807, 0.012628836, 0.023681683, 0.045...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/cross_validation_data/1/test.csv',\n",
       " '../data/cross_validation_data/1/train.csv',\n",
       " '../data/cross_validation_data/4/test.csv',\n",
       " '../data/cross_validation_data/4/train.csv',\n",
       " '../data/cross_validation_data/2/test.csv',\n",
       " '../data/cross_validation_data/2/train.csv',\n",
       " '../data/cross_validation_data/3/test.csv',\n",
       " '../data/cross_validation_data/3/train.csv',\n",
       " '../data/cross_validation_data/5/test.csv',\n",
       " '../data/cross_validation_data/5/train.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_cross_val_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetPairs(Dataset):\n",
    "    def __init__(self, d_data, cross_val_paths):\n",
    "        self.dataset = d_data\n",
    "        self.split_dict = self.get_id_cross_val(cross_val_paths)\n",
    "        \n",
    "        self.splited_data(k=1)\n",
    "        self.set_split(split='train')\n",
    "    \n",
    "    def read_csv(self, path):\n",
    "        d_data = pd.read_csv(path, sep='\\t')\n",
    "        return d_data\n",
    "    \n",
    "    def get_id_cross_val(self, paths):\n",
    "        data_dict = {}\n",
    "        path_dict = dict((file.split('/')[-2], file) for file in paths)\n",
    "        for k, path in path_dict.items():\n",
    "            train = self.read_csv(path)\n",
    "            id_train = train.id.tolist()\n",
    "            \n",
    "            path = path.replace('train.csv', 'test.csv')\n",
    "            test = self.read_csv(path)\n",
    "            id_test = test.id.tolist()\n",
    "            \n",
    "            data_dict[int(k)] = (id_train, id_test)\n",
    "            \n",
    "        return data_dict\n",
    "\n",
    "    def splited_data(self, k):\n",
    "        id_train, id_test = self.split_dict[k]\n",
    "        train = self.dataset[self.dataset.id.isin(id_train)]\n",
    "        test = self.dataset[self.dataset.id.isin(id_test)]\n",
    "        \n",
    "        train.reset_index(drop=True, inplace=True)\n",
    "        test.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        self.data_dict = {'train': (train, len(train)), 'test': (test, len(test))}\n",
    "        \n",
    "    def set_split(self, split='train'):\n",
    "        self.data, self.length = self.data_dict[split]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        q1 = self.data.loc[idx, \"q1_vector\"]\n",
    "        q2 = self.data.loc[idx, \"q2_vector\"]\n",
    "        x  = np.concatenate((dataset.data.loc[0, \"q1_vector\"], \n",
    "                             dataset.data.loc[0, \"q1_vector\"]))\n",
    "        y  = self.data.loc[idx, \"is_duplicate\"]\n",
    "        \n",
    "        x = torch.Tensor(x)\n",
    "        y = torch.LongTensor([y])\n",
    "        \n",
    "        return (x, y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, vec_size, l1, l2, num_class):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(vec_size*2, l1)\n",
    "        self.fc2 = nn.Linear(l1, l1)\n",
    "        self.fc3 = nn.Linear(l1, l2)\n",
    "        self.fc4 = nn.Linear(l2, num_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.fc4(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetPairs(d_data, file_cross_val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_q = 128\n",
    "l1 = 1024\n",
    "l2 =512\n",
    "num_class = 2\n",
    "\n",
    "batchsize = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier(vec_q, l1, l2, num_class)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model has 1,838,594 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'the model has {parameters:,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = 1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y, y_pred):\n",
    "    y_label = y_pred.argmax(dim=1)\n",
    "    n_correct = torch.eq(y, y_label).sum().item()\n",
    "    accuracy = (n_correct / len(y_label)) * 100\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_time(start, end):\n",
    "    duration = end - start\n",
    "    m = int(duration / 60)\n",
    "    s = int(duration % 60)\n",
    "    \n",
    "    return m, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 | 0m 32s\n",
      "\ttrain loss: 0.66 | train accuracy 63.08\n",
      "\tval loss: 0.66 | val accuracy 63.08\n",
      "epoch 2 | 0m 33s\n",
      "\ttrain loss: 0.66 | train accuracy 63.08\n",
      "\tval loss: 0.66 | val accuracy 63.08\n",
      "epoch 3 | 0m 32s\n",
      "\ttrain loss: 0.66 | train accuracy 63.08\n",
      "\tval loss: 0.66 | val accuracy 63.08\n",
      "epoch 4 | 0m 32s\n",
      "\ttrain loss: 0.66 | train accuracy 63.08\n",
      "\tval loss: 0.66 | val accuracy 63.08\n",
      "epoch 5 | 0m 32s\n",
      "\ttrain loss: 0.66 | train accuracy 63.08\n",
      "\tval loss: 0.66 | val accuracy 63.08\n",
      "epoch 6 | 0m 32s\n",
      "\ttrain loss: 0.66 | train accuracy 63.08\n",
      "\tval loss: 0.66 | val accuracy 63.08\n",
      "epoch 7 | 0m 33s\n",
      "\ttrain loss: 0.66 | train accuracy 63.08\n",
      "\tval loss: 0.66 | val accuracy 63.08\n",
      "epoch 8 | 0m 32s\n",
      "\ttrain loss: 0.66 | train accuracy 63.08\n",
      "\tval loss: 0.66 | val accuracy 63.08\n",
      "epoch 9 | 0m 31s\n",
      "\ttrain loss: 0.66 | train accuracy 63.08\n",
      "\tval loss: 0.66 | val accuracy 63.08\n",
      "epoch 10 | 0m 32s\n",
      "\ttrain loss: 0.66 | train accuracy 63.08\n",
      "\tval loss: 0.66 | val accuracy 63.08\n",
      "epoch 11 | 0m 31s\n",
      "\ttrain loss: 0.66 | train accuracy 63.08\n",
      "\tval loss: 0.66 | val accuracy 63.08\n",
      "epoch 12 | 0m 32s\n",
      "\ttrain loss: 0.66 | train accuracy 63.08\n",
      "\tval loss: 0.66 | val accuracy 63.08\n",
      "epoch 13 | 0m 31s\n",
      "\ttrain loss: 0.66 | train accuracy 63.08\n",
      "\tval loss: 0.66 | val accuracy 63.08\n",
      "epoch 14 | 0m 32s\n",
      "\ttrain loss: 0.66 | train accuracy 63.08\n",
      "\tval loss: 0.66 | val accuracy 63.08\n",
      "epoch 15 | 0m 32s\n",
      "\ttrain loss: 0.66 | train accuracy 63.08\n",
      "\tval loss: 0.66 | val accuracy 63.08\n",
      "epoch 16 | 0m 31s\n",
      "\ttrain loss: 0.66 | train accuracy 63.08\n",
      "\tval loss: 0.66 | val accuracy 63.08\n",
      "epoch 17 | 0m 32s\n",
      "\ttrain loss: 0.66 | train accuracy 63.08\n",
      "\tval loss: 0.66 | val accuracy 63.08\n",
      "epoch 18 | 0m 32s\n",
      "\ttrain loss: 0.66 | train accuracy 63.08\n",
      "\tval loss: 0.66 | val accuracy 63.08\n",
      "epoch 19 | 0m 31s\n",
      "\ttrain loss: 0.66 | train accuracy 63.08\n",
      "\tval loss: 0.66 | val accuracy 63.08\n",
      "epoch 20 | 0m 33s\n",
      "\ttrain loss: 0.66 | train accuracy 63.08\n",
      "\tval loss: 0.66 | val accuracy 63.08\n",
      "epoch 21 | 0m 32s\n",
      "\ttrain loss: 0.66 | train accuracy 63.08\n",
      "\tval loss: 0.66 | val accuracy 63.08\n",
      "epoch 22 | 0m 32s\n",
      "\ttrain loss: 0.66 | train accuracy 63.08\n",
      "\tval loss: 0.66 | val accuracy 63.08\n",
      "epoch 23 | 0m 32s\n",
      "\ttrain loss: 0.66 | train accuracy 63.08\n",
      "\tval loss: 0.66 | val accuracy 63.08\n",
      "epoch 24 | 0m 32s\n",
      "\ttrain loss: 0.66 | train accuracy 63.08\n",
      "\tval loss: 0.66 | val accuracy 63.08\n",
      "epoch 25 | 0m 32s\n",
      "\ttrain loss: 0.66 | train accuracy 63.08\n",
      "\tval loss: 0.66 | val accuracy 63.08\n",
      "epoch 26 | 0m 32s\n",
      "\ttrain loss: 0.66 | train accuracy 63.08\n",
      "\tval loss: 0.66 | val accuracy 63.08\n",
      "epoch 27 | 0m 32s\n",
      "\ttrain loss: 0.66 | train accuracy 63.08\n",
      "\tval loss: 0.66 | val accuracy 63.08\n",
      "epoch 28 | 0m 32s\n",
      "\ttrain loss: 0.66 | train accuracy 63.08\n",
      "\tval loss: 0.66 | val accuracy 63.08\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8800810ec5e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdata_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-5f6091287f8c>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     44\u001b[0m         x  = np.concatenate((dataset.data.loc[0, \"q1_vector\"], \n\u001b[1;32m     45\u001b[0m                              dataset.data.loc[0, \"q1_vector\"]))\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0my\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"is_duplicate\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1757\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1759\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1760\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_scalar\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;31m# a fast-path to scalar access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# if not, raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, index, col, takeable)\u001b[0m\n\u001b[1;32m   2905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2906\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2907\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2908\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2909\u001b[0m             \u001b[0;31m# GH 20629\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 51):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    running_loss = 0\n",
    "    running_accu = 0\n",
    "    running_loss_v = 0\n",
    "    running_accu_v = 0\n",
    "    \n",
    "    dataset.set_split(\"train\")\n",
    "    data_gen = DataLoader(dataset, batch_size=batchsize)\n",
    "    model.train()\n",
    "    for batch_index, (x, y) in enumerate(data_gen, 1):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.squeeze()\n",
    "        \n",
    "        out = model(x)\n",
    "        out = out.to(\"cpu\")\n",
    "        \n",
    "        loss = criterion(out, y)\n",
    "        loss_ = loss.item()\n",
    "        running_loss += (loss_ - running_loss) / batch_index\n",
    "        \n",
    "        accu = compute_accuracy(y, out)\n",
    "        running_accu += (accu - running_accu) / batch_index\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    dataset.set_split(\"test\")\n",
    "    data_gen = DataLoader(dataset, batch_size=batchsize)\n",
    "    model.eval()\n",
    "    for batch_index, (x, y) in enumerate(data_gen, 1):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.squeeze()\n",
    "        \n",
    "        out = model(x)\n",
    "        out = out.to(\"cpu\")\n",
    "        \n",
    "        loss = criterion(out, y)\n",
    "        loss_ = loss.item()\n",
    "        running_loss_v += (loss_ - running_loss_v) / batch_index\n",
    "        \n",
    "        accu = compute_accuracy(y, out)\n",
    "        running_accu_v += (accu - running_accu_v) / batch_index\n",
    "        \n",
    "    end = time.time()\n",
    "    m, s = compute_time(start, end)\n",
    "    \n",
    "    print(f'epoch {epoch} | {m}m {s}s')\n",
    "    print(f'\\ttrain loss: {running_loss:.2f} | train accuracy {running_accu:.2f}')\n",
    "    print(f'\\tval loss: {running_loss_v:.2f} | val accuracy {running_accu_v:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
